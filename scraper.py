import os
import json
import time
import asyncio
import re
from datetime import datetime
from playwright.async_api import async_playwright
from playwright_stealth import Stealth
from feishu_utils import FeishuClient

# ç¯å¢ƒå˜é‡
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET")
FEISHU_BASE_TOKEN = os.getenv("FEISHU_BASE_TOKEN")

def parse_date(date_str):
    if not date_str or any(x in date_str for x in ["ä¸é™", "è§è¯¦æƒ…", "æˆªæ­¢", "å°½å¿«", "é•¿æœŸ"]):
        return None
    match = re.search(r'(\d{4})[-\.å¹´/](\d{1,2})[-\.æœˆ/](\d{1,2})', date_str)
    if not match:
        match = re.search(r'(\d{1,2})[-\.æœˆ/](\d{1,2})', date_str)
        if match:
            year = datetime.now().year
            month, day = match.groups()
        else: return None
    else:
        year, month, day = match.groups()
    try:
        return f"{year}-{int(month):02d}-{int(day):02d}"
    except: return None

def is_expired(date_str):
    if not date_str: return False
    try:
        today = datetime.now().strftime("%Y-%m-%d")
        return date_str < today
    except: return False

def smart_fill(job):
    """å¼ºåˆ¶è¡¥å…¨æ‰€æœ‰ç©ºç™½ï¼Œç¡®ä¿é£ä¹¦è¡¨æ ¼æ— ç©ºè¡Œ"""
    name = job.get('å…¬å¸åç§°', '').upper()
    if not job.get('å…¬å¸ç±»å‹'):
        if any(x in name for x in ["LVMH", "LV", "DIOR", "CHANEL", "HERMES", "GUCCI", "å¤–ä¼", "å®æ´", "æ¬§è±é›…"]):
            job['å…¬å¸ç±»å‹'] = "å¤–ä¼"
        elif any(x in name for x in ["ä¸­ä¿¡", "é“¶è¡Œ", "å›½ä¼", "ä¸­é“", "ä¸­å»º"]):
            job['å…¬å¸ç±»å‹'] = "å›½ä¼"
        else:
            job['å…¬å¸ç±»å‹'] = "æ°‘ä¼"
    
    if not job.get('è¡Œä¸šç±»å‹'):
        if "å¥¢ä¾ˆå“" in name or job['å…¬å¸ç±»å‹'] == "å¤–ä¼": job['è¡Œä¸šç±»å‹'] = "å¥¢ä¾ˆå“/å¿«æ¶ˆ"
        elif "é“¶è¡Œ" in name or "è¯åˆ¸" in name: job['è¡Œä¸šç±»å‹'] = "é‡‘è"
        else: job['è¡Œä¸šç±»å‹'] = "ç»¼åˆ"
        
    if not job.get('å·¥ä½œåœ°ç‚¹'): job['å·¥ä½œåœ°ç‚¹'] = "å…¨å›½"
    if not job.get('æ‹›è˜å±Šåˆ«'): job['æ‹›è˜å±Šåˆ«'] = "2025/2026å±Š"
    return job

async def get_qiuzhifangzhou_data(page):
    print("æ­£åœ¨ä»æ±‚èŒæ–¹èˆŸå…¨é‡æŠ“å–ï¼ˆç»ˆæç¨³å¥æ¨¡å¼ï¼‰...")
    jobs = []
    try:
        await page.goto("https://www.qiuzhifangzhou.com/campus", wait_until="networkidle", timeout=90000)
        await asyncio.sleep(15) # ç»™è¶³æ¸²æŸ“æ—¶é—´
        
        page_num = 1
        while True:
            print(f"  - æ­£åœ¨è§£æç¬¬ {page_num} é¡µ...")
            await page.wait_for_selector(".ag-row", timeout=20000)
            
            # ä½¿ç”¨æ›´é²æ£’çš„ JS æå–ï¼Œå³ä½¿åˆ—é¡ºåºå˜äº†ä¹Ÿèƒ½æŠ“åˆ°
            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('.ag-row');
                    rows.forEach(row => {
                        const data = {};
                        const cells = row.querySelectorAll('.ag-cell');
                        cells.forEach(cell => {
                            const colId = cell.getAttribute('col-id');
                            const text = cell.innerText.trim();
                            if (colId) data[colId] = text;
                            if (colId === 'company') {
                                const a = cell.querySelector('a');
                                if (a) data['link'] = a.href;
                            }
                        });
                        
                        if (data.company && data.company !== "å…¬å¸") {
                            results.push({
                                'å…¬å¸åç§°': data.company.replace("æŠ•é€’å…¬å¸", "").trim(),
                                'æ‹›è˜å²—ä½': data.positions || "æ ¡æ‹›å²—ä½",
                                'å·¥ä½œåœ°ç‚¹': data.locations || "å…¨å›½",
                                'æ‹›è˜å±Šåˆ«': data.batch || "2025/2026å±Š",
                                'æˆªæ­¢æ—¶é—´': data.deadline || "",
                                'è¡Œä¸šç±»å‹': data.industry || "",
                                'å…¬å¸ç±»å‹': '',
                                'ç½‘ç”³é“¾æ¥': data.link || '',
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': 'https://www.qiuzhifangzhou.com/campus'
                            });
                        }
                    });
                    return results;
                }
            """)
            
            if not page_jobs: break
            for j in page_jobs:
                d = parse_date(j['æˆªæ­¢æ—¶é—´'])
                if not is_expired(d): jobs.append(j)
            
            # ç¿»é¡µ
            next_btn = await page.query_selector("button:has-text('ä¸‹ä¸€é¡µ'), .ag-paging-button:has-text('ä¸‹ä¸€é¡µ')")
            if next_btn and await next_btn.is_visible() and await next_btn.is_enabled():
                await next_btn.click()
                await asyncio.sleep(5)
                page_num += 1
            else: break
    except Exception as e: print(f"æ±‚èŒæ–¹èˆŸæŠ“å–ä¸­æ–­: {e}")
    return jobs

async def get_givemeoc_data(page):
    print("æ­£åœ¨ä» GiveMeOC æŠ“å–...")
    jobs = []
    try:
        await page.goto("https://www.givemeoc.com/", wait_until="networkidle", timeout=60000)
        await asyncio.sleep(10)
        items = await page.query_selector_all(".post-item")
        for item in items:
            try:
                title_el = await item.query_selector(".post-title a")
                if not title_el: continue
                title = await title_el.inner_text()
                href = await title_el.get_attribute("href")
                
                match = re.search(r'[\[ã€](.*?)[\]ã€‘](.*)', title)
                company = match.group(1).strip() if match else title.split(' ')[0]
                position = match.group(2).strip() if match else title
                
                jobs.append({
                    "å…¬å¸åç§°": company,
                    "æ‹›è˜å²—ä½": position,
                    "å·¥ä½œåœ°ç‚¹": "å…¨å›½",
                    "æ‹›è˜å±Šåˆ«": "2025/2026å±Š",
                    "æˆªæ­¢æ—¶é—´": "",
                    "è¡Œä¸šç±»å‹": "",
                    "å…¬å¸ç±»å‹": "",
                    "ç½‘ç”³é“¾æ¥": href,
                    "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": href
                })
            except: continue
    except Exception as e: print(f"GiveMeOC æŠ“å–å¤±è´¥: {e}")
    return jobs

async def main():
    if not all([FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN]):
        print("é”™è¯¯: é£ä¹¦é…ç½®ç¼ºå¤±")
        return

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        page = await context.new_page()
        await Stealth().apply_stealth_async(page)
        
        all_raw = []
        all_raw.extend(await get_qiuzhifangzhou_data(page))
        all_raw.extend(await get_givemeoc_data(page))
        await browser.close()

    valid_jobs = []
    seen_keys = set()
    for job in all_raw:
        job = smart_fill(job)
        company = job['å…¬å¸åç§°'].strip()
        position = job['æ‹›è˜å²—ä½'].strip()
        if not company or len(company) < 2: continue
        
        deadline = parse_date(job.get("æˆªæ­¢æ—¶é—´", ""))
        key = f"{company}|{position}"
        if key in seen_keys: continue
        seen_keys.add(key)
        
        row = {
            "æ›´æ–°æ—¥æœŸ": int(time.time() * 1000),
            "å…¬å¸åç§°": company,
            "å…¬å¸ç±»å‹": job['å…¬å¸ç±»å‹'],
            "è¡Œä¸šç±»å‹": job['è¡Œä¸šç±»å‹'],
            "æ‹›è˜å±Šåˆ«": job['æ‹›è˜å±Šåˆ«'],
            "å·¥ä½œåœ°ç‚¹": job['å·¥ä½œåœ°ç‚¹'],
            "æ‹›è˜å²—ä½": position,
            "ç½‘ç”³é“¾æ¥": {"link": job["ç½‘ç”³é“¾æ¥"], "text": "ç‚¹å‡»æŠ•é€’"} if job.get("ç½‘ç”³é“¾æ¥") else None,
            "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": {"link": job["æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥"], "text": "æŸ¥çœ‹å…¬å‘Š"} if job.get("æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥") else None,
            "æˆªæ­¢æ—¶é—´": int(time.mktime(time.strptime(deadline, "%Y-%m-%d"))) * 1000 if deadline else None
        }
        valid_jobs.append(row)

    print(f"æ—¥å¿—ï¼šæœ€ç»ˆç²¾å‡†åŒæ­¥ {len(valid_jobs)} æ¡å²—ä½")
    try:
        fs = FeishuClient(FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN)
        table_id = fs.get_table_id()
        if table_id:
            existing = fs.get_all_records(table_id)
            if existing:
                ids = [r['record_id'] for r in existing]
                for i in range(0, len(ids), 500): fs.delete_records(table_id, ids[i:i+500])
            for i in range(0, len(valid_jobs), 100): fs.add_records(table_id, valid_jobs[i:i+100])
            print("ğŸ‰ ç»ˆææ— æ•Œå®Œç¾åŒæ­¥æˆåŠŸï¼")
    except Exception as e: print(f"é£ä¹¦åŒæ­¥å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
