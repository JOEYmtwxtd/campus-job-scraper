import os
import json
import time
import asyncio
import re
from datetime import datetime
from playwright.async_api import async_playwright
from playwright_stealth import Stealth
from feishu_utils import FeishuClient

# ç¯å¢ƒå˜é‡
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET")
FEISHU_BASE_TOKEN = os.getenv("FEISHU_BASE_TOKEN")

def parse_date_to_ms(date_str):
    if not date_str or any(x in str(date_str) for x in ["ä¸é™", "è§è¯¦æƒ…", "æˆªæ­¢", "å°½å¿«", "é•¿æœŸ"]):
        return None
    # æå–æ•°å­—
    nums = re.findall(r'\d+', str(date_str))
    if not nums: return None
    try:
        year = datetime.now().year
        month, day = 1, 1
        if len(nums) >= 3:
            year, month, day = int(nums[0]), int(nums[1]), int(nums[2])
            if year < 100: year += 2000
        elif len(nums) == 2:
            # åªæœ‰æœˆæ—¥ï¼Œé»˜è®¤ä¸ºä»Šå¹´
            month, day = int(nums[0]), int(nums[1])
        dt = datetime(year, month, day)
        return int(time.mktime(dt.timetuple()) * 1000)
    except: return None

async def get_qiuzhifangzhou_data(page):
    print("ğŸš€ å¯åŠ¨æ±‚èŒæ–¹èˆŸæŠ“å– (å¢å¼ºç¨³å®šæ€§ä¿®å¤)...")
    jobs = []
    try:
        await page.goto("https://www.qiuzhifangzhou.com/campus", wait_until="networkidle", timeout=120000)
        await asyncio.sleep(15)
        
        page_num = 1
        while True:
            print(f"  ğŸ“„ æ­£åœ¨æŠ“å–ç¬¬ {page_num} é¡µ...")
            # æ˜¾å¼ç­‰å¾…è¡Œå…ƒç´ å‡ºç°å¹¶ç¨³å®š
            try:
                await page.wait_for_selector(".ag-row", timeout=30000)
                await asyncio.sleep(2) # é¢å¤–ç­‰å¾…æ¸²æŸ“
            except:
                print("  âš ï¸ ç­‰å¾…è¡¨æ ¼è¶…æ—¶ï¼Œå°è¯•ç»§ç»­æå–å†…å®¹...")
            
            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('.ag-row');
                    rows.forEach(row => {
                        const getT = (id) => {
                            const el = row.querySelector(`[col-id="${id}"]`);
                            return el ? el.innerText.trim() : "";
                        };
                        const company = getT("company").replace("æŠ•é€’å…¬å¸", "").trim();
                        const link_el = row.querySelector(`[col-id="company"] a`);
                        if (company && company !== "å…¬å¸") {
                            results.push({
                                'å…¬å¸åç§°': company,
                                'å…¬å¸ç±»å‹': getT("type"), 
                                'è¡Œä¸šç±»å‹': getT("industry"),
                                'æ‹›è˜å±Šåˆ«': getT("batch"),
                                'å·¥ä½œåœ°ç‚¹': getT("locations"),
                                'æ‹›è˜å²—ä½': getT("positions"),
                                'ç½‘ç”³é“¾æ¥': link_el ? link_el.href : '',
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': 'https://www.qiuzhifangzhou.com/campus',
                                'æˆªæ­¢æ—¶é—´': getT("deadline")
                            });
                        }
                    });
                    return results;
                }
            """)
            
            if page_jobs:
                jobs.extend(page_jobs)
                print(f"  âœ… ç¬¬ {page_num} é¡µæŠ“å–æˆåŠŸï¼Œæœ¬é¡µ {len(page_jobs)} æ¡ï¼Œç´¯è®¡: {len(jobs)} æ¡")
            else:
                print("  âš ï¸ æœ¬é¡µæœªå‘ç°æœ‰æ•ˆæ•°æ®ã€‚")
            
            # æ£€æŸ¥ä¸‹ä¸€é¡µæŒ‰é’®
            has_next = await page.evaluate("""
                () => {
                    const selectors = ['[ref="btNext"]', '.ag-paging-button-next', 'button[aria-label="Next Page"]', '.ag-icon-next'];
                    for (const sel of selectors) {
                        const btn = document.querySelector(sel);
                        if (btn) {
                            const parent = btn.closest('button') || btn.closest('[role="button"]') || btn;
                            const isDisabled = parent.disabled || parent.classList.contains('ag-disabled') || parent.getAttribute('aria-disabled') === 'true';
                            if (!isDisabled) {
                                parent.click();
                                return true;
                            }
                        }
                    }
                    return false;
                }
            """)
            
            if has_next:
                await asyncio.sleep(8)
                page_num += 1
                if page_num > 50: break
            else:
                print(f"  ğŸ æ±‚èŒæ–¹èˆŸç¿»é¡µç»“æŸï¼Œå…± {page_num} é¡µã€‚")
                break
    except Exception as e:
        print(f"  âŒ æ±‚èŒæ–¹èˆŸæŠ“å–å¤±è´¥: {e}")
    return jobs

async def get_givemeoc_data(page):
    print("ğŸš€ å¯åŠ¨ GiveMeOC æŠ“å–...")
    jobs = []
    try:
        await page.goto("https://www.givemeoc.com/", wait_until="networkidle", timeout=90000)
        await asyncio.sleep(10)
        await page.wait_for_selector('table')
        
        total_pages = await page.evaluate("""
            () => {
                const pageLinks = document.querySelectorAll('a[href*="paged="]');
                let max = 1;
                pageLinks.forEach(link => {
                    const match = link.href.match(/paged=(\\d+)/);
                    if (match && parseInt(match[1]) > max) max = parseInt(match[1]);
                });
                return Math.min(max, 100); 
            }
        """)
        print(f"  ğŸ“‘ æ£€æµ‹åˆ°å…± {total_pages} é¡µï¼Œå¼€å§‹æŠ“å–...")
        
        for p in range(1, total_pages + 1):
            if p > 1:
                await page.goto(f"https://www.givemeoc.com/?paged={p}", wait_until="networkidle")
                await asyncio.sleep(5)
            
            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('tr');
                    rows.forEach(row => {
                        const cells = Array.from(row.querySelectorAll('td'));
                        if (cells.length >= 10) {
                            const company = cells[0].innerText.trim();
                            if (company === "å…¬å¸" || !company) return;
                            const a = row.querySelector('a');
                            results.push({
                                'å…¬å¸åç§°': company,
                                'å…¬å¸ç±»å‹': cells[1].innerText.trim(),
                                'è¡Œä¸šç±»å‹': cells[2].innerText.trim(),
                                'æ‹›è˜å²—ä½': cells[6].innerText.trim(),
                                'æ‹›è˜å±Šåˆ«': cells[4].innerText.trim(),
                                'å·¥ä½œåœ°ç‚¹': cells[5].innerText.trim(),
                                'ç½‘ç”³é“¾æ¥': a ? a.href : '',
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': a ? a.href : '',
                                'æˆªæ­¢æ—¶é—´': cells[9].innerText.trim()
                            });
                        }
                    });
                    return results;
                }
            """)
            jobs.extend(page_jobs)
            print(f"  âœ… ç¬¬ {p} é¡µæŠ“å–æˆåŠŸï¼Œç´¯è®¡: {len(jobs)} æ¡")
    except Exception as e:
        print(f"  âŒ GiveMeOC æŠ“å–å¤±è´¥: {e}")
    return jobs

async def get_tencent_docs_data(page):
    print("ğŸš€ å¯åŠ¨è…¾è®¯æ–‡æ¡£æŠ“å–...")
    jobs = []
    url = "https://docs.qq.com/sheet/DS29Pb3pLRExVa0xp?tab=BB08J2"
    try:
        await page.goto(url, wait_until="networkidle", timeout=120000)
        await asyncio.sleep(15)
        
        # è…¾è®¯æ–‡æ¡£é€šå¸¸éœ€è¦æ¨¡æ‹Ÿæ»šåŠ¨æ¥åŠ è½½ DOM æ•°æ®
        for _ in range(5):
            await page.mouse.wheel(0, 2000)
            await asyncio.sleep(2)
            
        page_jobs = await page.evaluate("""
            () => {
                const results = [];
                // è…¾è®¯æ–‡æ¡£çš„è¡Œé€šå¸¸ç”±ç‰¹å®šç±»åæ ‡è¯†ï¼Œè¿™é‡Œå°è¯•é€šç”¨é€‰æ‹©å™¨
                const rows = Array.from(document.querySelectorAll('.canvas-container + div div[role="row"], .excel-container tr'));
                
                // å¦‚æœæ˜¯ canvas æ¸²æŸ“ï¼Œå°è¯•ä» window å˜é‡æˆ– DOM æ–‡æœ¬ä¸­æå–
                // è¿™é‡Œä½¿ç”¨ä¸€ç§å¯å‘å¼æ–¹æ³•ï¼šæŸ¥æ‰¾åŒ…å«å…¬å¸åç§°å’Œé“¾æ¥çš„å®¹å™¨
                const cellTexts = Array.from(document.querySelectorAll('.text-cell, .cell-content, td'));
                
                // è…¾è®¯æ–‡æ¡£ DOM ç»“æ„å¤æ‚ï¼Œè¿™é‡Œé‡‡ç”¨åŸºäºè¡Œä½ç½®çš„å¯å‘å¼æå–
                const rowElements = document.querySelectorAll('.web-excel-row');
                rowElements.forEach(row => {
                    const cells = Array.from(row.querySelectorAll('.web-excel-cell'));
                    if (cells.length >= 10) {
                        const getC = (idx) => cells[idx] ? cells[idx].innerText.trim() : "";
                        const company = getC(1); // Båˆ—
                        if (!company || company === "ä¼ä¸š/æ‹›è˜å•ä½åç§°") return;
                        
                        const link_el = cells[9] ? cells[9].querySelector('a') : null; // Jåˆ—
                        const notice_el = cells[10] ? cells[10].querySelector('a') : null; // Kåˆ—
                        
                        results.push({
                            'å…¬å¸åç§°': company,
                            'å…¬å¸ç±»å‹': getC(2),
                            'è¡Œä¸šç±»å‹': getT(3),
                            'æ‹›è˜å±Šåˆ«': getC(4) + " " + getC(5),
                            'å·¥ä½œåœ°ç‚¹': getC(7),
                            'æ‹›è˜å²—ä½': getC(6),
                            'ç½‘ç”³é“¾æ¥': link_el ? link_el.href : getC(9),
                            'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': notice_el ? notice_el.href : getC(10),
                            'æˆªæ­¢æ—¶é—´': getC(8)
                        });
                    }
                });
                return results;
            }
        """)
        
        # å¦‚æœ DOM æŠ“å–å¤±è´¥ï¼Œå°è¯•æ›´é€šç”¨çš„æ–‡æœ¬åŒ¹é…
        if not page_jobs:
            print("  âš ï¸ DOM æŠ“å–å¤±è´¥ï¼Œå°è¯•æ–‡æœ¬æ¨¡å¼æŠ“å–...")
            # è¿™é‡Œçš„é€»è¾‘å¯ä»¥æ ¹æ®å®é™…é¡µé¢è¿›ä¸€æ­¥å¾®è°ƒ
            
        jobs.extend(page_jobs)
        print(f"  âœ… è…¾è®¯æ–‡æ¡£æŠ“å–åˆ° {len(jobs)} æ¡æ•°æ®")
    except Exception as e:
        print(f"  âŒ è…¾è®¯æ–‡æ¡£æŠ“å–å¤±è´¥: {e}")
    return jobs

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        page = await context.new_page()
        await Stealth().apply_stealth_async(page)
        
        all_raw = []
        all_raw.extend(await get_qiuzhifangzhou_data(page))
        all_raw.extend(await get_givemeoc_data(page))
        all_raw.extend(await get_tencent_docs_data(page))
        await browser.close()

    valid_jobs = []
    seen_keys = set()
    now_ms = int(time.time() * 1000)
    
    for job in all_raw:
        company = str(job.get('å…¬å¸åç§°', '')).strip()
        position = str(job.get('æ‹›è˜å²—ä½', '')).strip()
        if not company or not position or company == "undefined": continue
        
        deadline_ms = parse_date_to_ms(job.get("æˆªæ­¢æ—¶é—´", ""))
        key = f"{company}|{position}"
        if key in seen_keys: continue
        seen_keys.add(key)
        
        valid_jobs.append({
            "æ›´æ–°æ—¥æœŸ": now_ms,
            "å…¬å¸åç§°": company,
            "å…¬å¸ç±»å‹": job.get('å…¬å¸ç±»å‹', ''),
            "è¡Œä¸šç±»å‹": job.get('è¡Œä¸šç±»å‹', ''),
            "æ‹›è˜å±Šåˆ«": job.get('æ‹›è˜å±Šåˆ«', ''),
            "å·¥ä½œåœ°ç‚¹": job.get('å·¥ä½œåœ°ç‚¹', ''),
            "æ‹›è˜å²—ä½": position,
            "ç½‘ç”³é“¾æ¥": {"link": job["ç½‘ç”³é“¾æ¥"], "text": "ç‚¹å‡»æŠ•é€’"} if job.get("ç½‘ç”³é“¾æ¥") and "http" in str(job["ç½‘ç”³é“¾æ¥"]) else None,
            "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": {"link": job["æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥"], "text": "æŸ¥çœ‹å…¬å‘Š"} if job.get("æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥") and "http" in str(job["æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥"]) else None,
            "æˆªæ­¢æ—¶é—´": deadline_ms
        })

    print(f"ğŸ“Š æ±‡æ€»ï¼šæŠ“å– {len(all_raw)} æ¡ï¼Œå»é‡å {len(valid_jobs)} æ¡ã€‚åŒæ­¥é£ä¹¦...")
    
    try:
        fs = FeishuClient(FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN)
        table_id = fs.get_table_id()
        if table_id:
            existing = fs.get_all_records(table_id)
            if existing:
                ids = [r['record_id'] for r in existing]
                fs.delete_records(table_id, ids)
            fs.add_records(table_id, valid_jobs)
            print(f"ğŸ‰ åŒæ­¥å®Œæˆï¼å…±æ›´æ–° {len(valid_jobs)} æ¡å²—ä½ã€‚")
    except Exception as e:
        print(f"  âŒ é£ä¹¦åŒæ­¥å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
