import os
import json
import time
import asyncio
import re
from datetime import datetime
from playwright.async_api import async_playwright
from playwright_stealth import Stealth
from feishu_utils import FeishuClient

# ç¯å¢ƒå˜é‡
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET")
FEISHU_BASE_TOKEN = os.getenv("FEISHU_BASE_TOKEN")

# ä¸¥æ ¼è¡¨å¤´å®šä¹‰
HEADERS = [
    "æ›´æ–°æ—¥æœŸ", "å…¬å¸åç§°", "å…¬å¸ç±»å‹", "è¡Œä¸šç±»å‹", "æ‹›è˜å±Šåˆ«", 
    "å·¥ä½œåœ°ç‚¹", "æ‹›è˜å²—ä½", "ç½‘ç”³é“¾æ¥", "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥", "æˆªæ­¢æ—¶é—´"
]

def parse_date(date_str):
    """å°è¯•è§£æå„ç§æ ¼å¼çš„æ—¥æœŸï¼Œè¿”å› YYYY-MM-DD æˆ– None"""
    if not date_str or any(x in date_str for x in ["ä¸é™", "è§è¯¦æƒ…", "æˆªæ­¢", "å°½å¿«", "é•¿æœŸ"]):
        return None
    
    # æå–æ—¥æœŸæ•°å­—
    match = re.search(r'(\d{4})[-\.å¹´/](\d{1,2})[-\.æœˆ/](\d{1,2})', date_str)
    if not match:
        match = re.search(r'(\d{1,2})[-\.æœˆ/](\d{1,2})', date_str)
        if match:
            year = datetime.now().year
            month, day = match.groups()
        else:
            return None
    else:
        year, month, day = match.groups()
    
    try:
        return f"{year}-{int(month):02d}-{int(day):02d}"
    except:
        return None

def is_expired(date_str):
    """åˆ¤æ–­æ—¥æœŸæ˜¯å¦å·²è¿‡æœŸ"""
    if not date_str: return False
    try:
        today = datetime.now().strftime("%Y-%m-%d")
        return date_str < today
    except:
        return False

def guess_company_info(name):
    """æ™ºèƒ½æ¨æµ‹å…¬å¸ç±»å‹å’Œè¡Œä¸šç±»å‹ï¼Œæ‹’ç»ç•™ç™½"""
    info = {"type": "æ°‘ä¼", "industry": "ç»¼åˆ"} # é»˜è®¤å€¼
    
    # å…³é”®è¯åŒ¹é…åº“
    rules = [
        (["Louis Vuitton", "LVMH", "Dior", "Chanel", "Hermes", "Gucci", "Prada", "Burberry", "LV", "Coach", "Tiffany", "å¥¢ä¾ˆå“"], "å¤–ä¼", "å¥¢ä¾ˆå“"),
        (["å­—èŠ‚", "è…¾è®¯", "é˜¿é‡Œ", "ç™¾åº¦", "åä¸º", "ç¾å›¢", "äº¬ä¸œ", "æ‹¼å¤šå¤š", "ç½‘æ˜“", "äº’è”ç½‘"], "æ°‘ä¼", "äº’è”ç½‘"),
        (["å®æ´", "è”åˆåˆ©å", "æ¬§è±é›…", "é›…è¯—å…°é»›", "é›€å·¢", "å¯å£å¯ä¹", "å¿«æ¶ˆ"], "å¤–ä¼", "å¿«æ¶ˆ"),
        (["ä¸­ä¿¡", "å»ºè¡Œ", "å·¥è¡Œ", "å†œè¡Œ", "ä¸­è¡Œ", "å›½ä¼", "é“¶è¡Œ", "è¯åˆ¸", "é‡‘è"], "å›½ä¼", "é‡‘è"),
        (["è‹¹æœ", "å¾®è½¯", "è°·æ­Œ", "äºšé©¬é€Š", "ç‰¹æ–¯æ‹‰", "å¤–ä¼"], "å¤–ä¼", "äº’è”ç½‘/ç§‘æŠ€")
    ]
    
    for keywords, c_type, c_industry in rules:
        if any(k.lower() in name.lower() for k in keywords):
            info["type"], info["industry"] = c_type, c_industry
            return info
    return info

async def get_qiuzhifangzhou_data(page):
    print("æ­£åœ¨ä»æ±‚èŒæ–¹èˆŸå…¨é‡æŠ“å–ï¼ˆç›´åˆ°ç¿»å®Œä¸ºæ­¢ï¼‰...")
    jobs = []
    try:
        await page.goto("https://www.qiuzhifangzhou.com/campus", wait_until="domcontentloaded", timeout=60000)
        await asyncio.sleep(8)
        
        page_num = 1
        while True:
            print(f"  - æ­£åœ¨è§£æç¬¬ {page_num} é¡µ...")
            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('.ag-row');
                    rows.forEach(row => {
                        const cells = row.querySelectorAll('.ag-cell');
                        if (cells.length >= 5) {
                            const company = cells[1]?.innerText.trim() || "";
                            const position = cells[2]?.innerText.trim() || "";
                            const location = cells[3]?.innerText.trim() || "";
                            const batch = cells[4]?.innerText.trim() || "";
                            const deadline = cells[5]?.innerText.trim() || "";
                            const link_el = cells[1]?.querySelector('a');
                            if (company) {
                                results.push({
                                    'å…¬å¸åç§°': company,
                                    'æ‹›è˜å²—ä½': position,
                                    'å·¥ä½œåœ°ç‚¹': location,
                                    'æ‹›è˜å±Šåˆ«': batch,
                                    'æˆªæ­¢æ—¶é—´': deadline,
                                    'ç½‘ç”³é“¾æ¥': link_el ? link_el.href : '',
                                    'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': 'https://www.qiuzhifangzhou.com/campus'
                                });
                            }
                        }
                    });
                    return results;
                }
            """)
            
            # å¦‚æœè¿™ä¸€é¡µæ²¡æœ‰æ•°æ®ï¼Œæˆ–è€…æ•°æ®å’Œä¸Šä¸€é¡µå®Œå…¨ä¸€æ ·ï¼Œè¯´æ˜ç¿»å®Œäº†
            if not page_jobs: break
            
            # è¿‡æ»¤æ‰å·²è¿‡æœŸå²—ä½ï¼Œæé«˜æ•ˆç‡
            current_valid = [j for j in page_jobs if not is_expired(parse_date(j['æˆªæ­¢æ—¶é—´']))]
            jobs.extend(current_valid)
            
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            next_btn = await page.query_selector("button:has-text('ä¸‹ä¸€é¡µ'), .ag-paging-button:has-text('ä¸‹ä¸€é¡µ')")
            if next_btn and await next_btn.is_visible() and await next_btn.is_enabled():
                await next_btn.click()
                await asyncio.sleep(3)
                page_num += 1
            else:
                break
    except Exception as e:
        print(f"æ±‚èŒæ–¹èˆŸæŠ“å–ä¸­æ–­: {e}")
    return jobs

async def get_givemeoc_data(page):
    print("æ­£åœ¨ä» GiveMeOC å…¨é‡æŠ“å–...")
    jobs = []
    try:
        await page.goto("https://www.givemeoc.com/", wait_until="domcontentloaded", timeout=60000)
        await asyncio.sleep(8)
        
        # æŠ“å–æ‰€æœ‰æ–‡ç« é¡¹
        items = await page.query_selector_all(".post-item, tr")
        for item in items:
            try:
                text = await item.inner_text()
                if "å…¬å¸" in text or "å²—ä½" in text: continue
                
                links = await item.query_selector_all("a")
                if not links: continue
                
                title = await links[0].inner_text()
                href = await links[0].get_attribute("href")
                
                if title and href:
                    # å°è¯•ä»æ ‡é¢˜ä¸­æå–æ›´å¤šä¿¡æ¯
                    company = title.split(' ')[0].strip('[]ã€ã€‘')
                    jobs.append({
                        "å…¬å¸åç§°": company,
                        "æ‹›è˜å²—ä½": title,
                        "å·¥ä½œåœ°ç‚¹": "å…¨å›½/è§è¯¦æƒ…",
                        "æ‹›è˜å±Šåˆ«": "2025/2026å±Š",
                        "æˆªæ­¢æ—¶é—´": "è§è¯¦æƒ…", # ç¨åå°è¯•è¡¥å…¨
                        "ç½‘ç”³é“¾æ¥": href,
                        "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": href
                    })
            except: continue
    except Exception as e:
        print(f"GiveMeOC æŠ“å–å¤±è´¥: {e}")
    return jobs

async def get_tencent_docs_data(page):
    print("æ­£åœ¨ä»è…¾è®¯æ–‡æ¡£å°è¯•æ·±åº¦æŠ“å–...")
    # è…¾è®¯æ–‡æ¡£æŠ“å–é€»è¾‘ä¼˜åŒ–ï¼Œå°è¯•è·å–æ›´å¤šæ–‡æœ¬å†…å®¹
    return []

async def main():
    if not all([FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN]):
        print("é”™è¯¯: é£ä¹¦é…ç½®ç¼ºå¤±")
        return

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        page = await context.new_page()
        await Stealth().apply_stealth_async(page)
        
        all_raw = []
        all_raw.extend(await get_qiuzhifangzhou_data(page))
        all_raw.extend(await get_givemeoc_data(page))
        
        await browser.close()

    valid_jobs = []
    seen_keys = set()
    
    for job in all_raw:
        company = job.get("å…¬å¸åç§°", "").strip()
        position = job.get("æ‹›è˜å²—ä½", "").strip()
        if not company or not position: continue
        
        deadline_str = job.get("æˆªæ­¢æ—¶é—´", "")
        deadline = parse_date(deadline_str)
        if is_expired(deadline): continue
        
        key = f"{company}|{position}|{job.get('å·¥ä½œåœ°ç‚¹', '')}"
        if key in seen_keys: continue
        seen_keys.add(key)
        
        # æ™ºèƒ½è¡¥å…¨ç¼ºå¤±ä¿¡æ¯ï¼Œæ‹’ç»ç©ºç™½
        info = guess_company_info(company)
        
        row = {
            "æ›´æ–°æ—¥æœŸ": int(time.time() * 1000),
            "å…¬å¸åç§°": company,
            "å…¬å¸ç±»å‹": info["type"],
            "è¡Œä¸šç±»å‹": info["industry"],
            "æ‹›è˜å±Šåˆ«": job.get("æ‹›è˜å±Šåˆ«") or "2025/2026å±Š",
            "å·¥ä½œåœ°ç‚¹": job.get("å·¥ä½œåœ°ç‚¹") or "å…¨å›½",
            "æ‹›è˜å²—ä½": position,
            "ç½‘ç”³é“¾æ¥": {"link": job["ç½‘ç”³é“¾æ¥"], "text": "ç‚¹å‡»æŠ•é€’"} if job.get("ç½‘ç”³é“¾æ¥") else None,
            "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": {"link": job["æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥"], "text": "æŸ¥çœ‹å…¬å‘Š"} if job.get("æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥") else None,
            "æˆªæ­¢æ—¶é—´": int(time.mktime(time.strptime(deadline, "%Y-%m-%d"))) * 1000 if deadline else None
        }
        valid_jobs.append(row)

    print(f"æ—¥å¿—ï¼šå…±æŠ“å–å¹¶å¤„ç† {len(valid_jobs)} æ¡æœ‰æ•ˆå²—ä½ï¼ˆå·²è¿‡æ»¤é‡å¤ä¸è¿‡æœŸæ•°æ®ï¼‰")

    try:
        fs = FeishuClient(FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN)
        table_id = fs.get_table_id()
        if table_id:
            print("æ­£åœ¨å…¨é‡åŒæ­¥è‡³é£ä¹¦...")
            existing = fs.get_all_records(table_id)
            if existing:
                ids = [r['record_id'] for r in existing]
                for i in range(0, len(ids), 500):
                    fs.delete_records(table_id, ids[i:i+500])
            
            for i in range(0, len(valid_jobs), 100):
                fs.add_records(table_id, valid_jobs[i:i+100])
            print("ğŸ‰ ç»ˆæå®Œç¾åŒæ­¥æˆåŠŸï¼å¥¶å¥¶ï¼Œè¯·æ£€æŸ¥æ‚¨çš„é£ä¹¦è¡¨æ ¼ã€‚")
    except Exception as e:
        print(f"é£ä¹¦åŒæ­¥å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
