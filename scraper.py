import os
import json
import time
import asyncio
import re
from datetime import datetime
from playwright.async_api import async_playwright
from playwright_stealth import Stealth
from feishu_utils import FeishuClient

# ç¯å¢ƒå˜é‡
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET")
FEISHU_BASE_TOKEN = os.getenv("FEISHU_BASE_TOKEN")

def parse_date_to_ms(date_str):
    if not date_str or any(x in date_str for x in ["ä¸é™", "è§è¯¦æƒ…", "æˆªæ­¢", "å°½å¿«", "é•¿æœŸ"]):
        return None
    nums = re.findall(r'\d+', date_str)
    if not nums: return None
    try:
        year = datetime.now().year
        month, day = 1, 1
        if len(nums) >= 3:
            year, month, day = int(nums[0]), int(nums[1]), int(nums[2])
            if year < 100: year += 2000
        elif len(nums) == 2:
            month, day = int(nums[0]), int(nums[1])
        dt = datetime(year, month, day)
        return int(time.mktime(dt.timetuple()) * 1000)
    except: return None

async def get_qiuzhifangzhou_data(page):
    print("ğŸš€ å¯åŠ¨æ±‚èŒæ–¹èˆŸã€æš´åŠ›ç¿»é¡µã€‘æ¨¡å¼...")
    jobs = []
    try:
        await page.goto("https://www.qiuzhifangzhou.com/campus", wait_until="networkidle", timeout=120000)
        await asyncio.sleep(20)

        page_num = 1
        while True:
            print(f"  ğŸ“„ æ­£åœ¨å…¨åŠ›æŠ“å–ç¬¬ {page_num} é¡µ...")
            await page.wait_for_selector(".ag-row", timeout=30000)

            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('.ag-row');
                    rows.forEach(row => {
                        const getT = (id) => row.querySelector(`[col-id="${id}"]`)?.innerText.trim() || "";
                        const company = getT("company").replace("æŠ•é€’å…¬å¸", "").trim();
                        const link_el = row.querySelector(`[col-id="company"] a`);
                        if (company && company !== "å…¬å¸") {
                            results.push({
                                'å…¬å¸åç§°': company,
                                'å…¬å¸ç±»å‹': getT("type"),
                                'è¡Œä¸šç±»å‹': getT("industry"),
                                'æ‹›è˜å±Šåˆ«': getT("batch"),
                                'å·¥ä½œåœ°ç‚¹': getT("locations"),
                                'æ‹›è˜å²—ä½': getT("positions"),
                                'ç½‘ç”³é“¾æ¥': link_el ? link_el.href : '',
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': 'https://www.qiuzhifangzhou.com/campus',
                                'æˆªæ­¢æ—¶é—´': getT("deadline")
                            });
                        }
                    });
                    return results;
                }
            """)

            if not page_jobs:
                print("  âš ï¸ æœ¬é¡µæ²¡æŠ“åˆ°æ•°æ®ï¼Œå°è¯•å†ç­‰ä¼šå„¿...")
                await asyncio.sleep(5)
                page_num += 1
                if page_num > 50:
                    break
                continue

            jobs.extend(page_jobs)
            print(f"  âœ… ç¬¬ {page_num} é¡µæŠ“å–æˆåŠŸï¼Œå½“å‰ç´¯è®¡: {len(jobs)} æ¡")

            # æ£€æŸ¥ä¸‹ä¸€é¡µæŒ‰é’®æ˜¯å¦å­˜åœ¨ä¸”å¯ç”¨
            can_go_next = await page.evaluate("""
                () => {
                    const nextBtn = document.querySelector('[ref="btNext"]') ||
                                   document.querySelector('.ag-paging-button[ref="btNext"]') ||
                                   document.querySelector('button[aria-label="Next Page"]');
                    if (!nextBtn) return false;
                    return !nextBtn.disabled && !nextBtn.classList.contains('ag-disabled');
                }
            """)

            if can_go_next:
                await page.click('[ref="btNext"], .ag-paging-button[ref="btNext"], button[aria-label="Next Page"]')
                await asyncio.sleep(8)
                page_num += 1
            else:
                print(f"  ğŸ å·²ç¿»åˆ°æœ€åä¸€é¡µï¼Œå…± {page_num} é¡µã€‚")
                break
    except Exception as e:
        print(f"  âŒ æŠ“å–ä¸­æ–­: {e}")
    return jobs

async def get_givemeoc_data(page):
    print("ğŸš€ å¯åŠ¨ GiveMeOC æŠ“å–...")
    jobs = []
    try:
        await page.goto("https://www.givemeoc.com/", wait_until="networkidle", timeout=90000)
        await asyncio.sleep(15)
        await page.wait_for_selector('table')

        # è·å–æ€»é¡µæ•°
        total_pages = await page.evaluate("""
            () => {
                const pageLinks = document.querySelectorAll('a[href*="paged="]');
                let max = 1;
                pageLinks.forEach(link => {
                    const match = link.href.match(/paged=(\\d+)/);
                    if (match) max = Math.max(max, parseInt(match[1]));
                });
                return max;
            }
        """)
        print(f"  ğŸ“Š GiveMeOC å…± {total_pages} é¡µ")

        page_num = 1
        while page_num <= total_pages:
            print(f"  ğŸ“„ æ­£åœ¨æŠ“å– GiveMeOC ç¬¬ {page_num}/{total_pages} é¡µ...")

            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const rows = document.querySelectorAll('table tr');
                    rows.forEach(row => {
                        const cells = Array.from(row.querySelectorAll('td'));
                        if (cells.length >= 10) {
                            const company = cells[0].innerText.trim();
                            if (!company || company === 'å…¬å¸åç§°') return;
                            const linkCell = cells[10] || cells[11];
                            const a = linkCell ? linkCell.querySelector('a') : row.querySelector('a');
                            results.push({
                                'å…¬å¸åç§°': company,
                                'å…¬å¸ç±»å‹': cells[1].innerText.trim(),
                                'è¡Œä¸šç±»å‹': cells[2].innerText.trim(),
                                'æ‹›è˜å²—ä½': cells[6].innerText.trim(),
                                'æ‹›è˜å±Šåˆ«': cells[4].innerText.trim(),
                                'å·¥ä½œåœ°ç‚¹': cells[5].innerText.trim(),
                                'ç½‘ç”³é“¾æ¥': a ? a.href : '',
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': a ? a.href : '',
                                'æˆªæ­¢æ—¶é—´': cells[9].innerText.trim()
                            });
                        }
                    });
                    return results;
                }
            """)

            if page_jobs:
                jobs.extend(page_jobs)
                print(f"  âœ… GiveMeOC ç¬¬ {page_num} é¡µæŠ“å–åˆ° {len(page_jobs)} æ¡ï¼Œç´¯è®¡: {len(jobs)} æ¡")

            page_num += 1
            if page_num <= total_pages:
                # ä½¿ç”¨URLç›´æ¥è·³è½¬åˆ°ä¸‹ä¸€é¡µ
                next_url = f"https://www.givemeoc.com/?paged={page_num}"
                await page.goto(next_url, wait_until="networkidle", timeout=60000)
                await asyncio.sleep(5)

        print(f"  ğŸ GiveMeOC æŠ“å–å®Œæˆï¼Œå…± {total_pages} é¡µã€‚")
    except Exception as e:
        print(f"  âŒ GiveMeOC å¤±è´¥: {e}")
    return jobs

async def get_careercenter_data(page):
    print("ğŸš€ å¯åŠ¨ CareerCenter æŠ“å–...")
    jobs = []
    try:
        await page.goto("https://www.careercenter.com/jobs", wait_until="networkidle", timeout=90000)
        await asyncio.sleep(15)

        page_num = 1
        while True:
            print(f"  ğŸ“„ æ­£åœ¨æŠ“å– CareerCenter ç¬¬ {page_num} é¡µ...")
            page_jobs = await page.evaluate("""
                () => {
                    const results = [];
                    const jobItems = document.querySelectorAll('.job-item');
                    jobItems.forEach(item => {
                        const company = item.querySelector('.company')?.innerText.trim() || '';
                        const position = item.querySelector('.position')?.innerText.trim() || '';
                        const deadline = item.querySelector('.deadline')?.innerText.trim() || '';
                        const link = item.querySelector('.apply-link')?.href || '';
                        if (company && position) {
                            results.push({
                                'å…¬å¸åç§°': company,
                                'å…¬å¸ç±»å‹': '',
                                'è¡Œä¸šç±»å‹': '',
                                'æ‹›è˜å±Šåˆ«': '',
                                'å·¥ä½œåœ°ç‚¹': '',
                                'æ‹›è˜å²—ä½': position,
                                'ç½‘ç”³é“¾æ¥': link,
                                'æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥': link,
                                'æˆªæ­¢æ—¶é—´': deadline
                            });
                        }
                    });
                    return results;
                }
            """)

            if page_jobs:
                jobs.extend(page_jobs)
                print(f"  âœ… CareerCenter ç¬¬ {page_num} é¡µæŠ“å–åˆ° {len(page_jobs)} æ¡ï¼Œç´¯è®¡: {len(jobs)} æ¡")

            next_btn = await page.query_selector('button.next, a[rel="next"], .pagination .next')
            if next_btn and await next_btn.is_enabled() and await next_btn.is_visible():
                await next_btn.click()
                await asyncio.sleep(8)
                page_num += 1
            else:
                print(f"  ğŸ CareerCenter å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œå…± {page_num} é¡µã€‚")
                break
    except Exception as e:
        print(f"  âŒ CareerCenter å¤±è´¥: {e}")
    return jobs

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        page = await context.new_page()
        await Stealth().apply_stealth_async(page)
        
        all_raw = []
        all_raw.extend(await get_qiuzhifangzhou_data(page))
        all_raw.extend(await get_givemeoc_data(page))
        all_raw.extend(await get_careercenter_data(page))
        await browser.close()

    valid_jobs = []
    seen_keys = set()
    now_ms = int(time.time() * 1000)
    
    for job in all_raw:
        company = job['å…¬å¸åç§°'].strip()
        position = job['æ‹›è˜å²—ä½'].strip()
        if not company or not position: continue
        
        deadline_ms = parse_date_to_ms(job.get("æˆªæ­¢æ—¶é—´", ""))
        # å³ä½¿æ²¡æŠ“åˆ°æ—¥æœŸä¹Ÿä¿ç•™ï¼Œé˜²æ­¢æ¼æ‰å²—ä½
        key = f"{company}|{position}"
        if key in seen_keys: continue
        seen_keys.add(key)
        
        valid_jobs.append({
            "æ›´æ–°æ—¥æœŸ": now_ms,
            "å…¬å¸åç§°": company,
            "å…¬å¸ç±»å‹": job.get('å…¬å¸ç±»å‹', ''),
            "è¡Œä¸šç±»å‹": job.get('è¡Œä¸šç±»å‹', ''),
            "æ‹›è˜å±Šåˆ«": job.get('æ‹›è˜å±Šåˆ«', ''),
            "å·¥ä½œåœ°ç‚¹": job.get('å·¥ä½œåœ°ç‚¹', ''),
            "æ‹›è˜å²—ä½": position,
            "ç½‘ç”³é“¾æ¥": {"link": job["ç½‘ç”³é“¾æ¥"], "text": "ç‚¹å‡»æŠ•é€’"} if job.get("ç½‘ç”³é“¾æ¥") else None,
            "æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥": {"link": job["æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥"], "text": "æŸ¥çœ‹å…¬å‘Š"} if job.get("æ‹›è˜å…¬å‘ŠåŸæ–‡é“¾æ¥") else None,
            "æˆªæ­¢æ—¶é—´": deadline_ms
        })

    print(f"ğŸ“Š ä»»åŠ¡æ±‡æ€»ï¼šæ€»è®¡æŠ“å– {len(valid_jobs)} æ¡æœ‰æ•ˆå²—ä½ã€‚æ­£åœ¨åŒæ­¥åˆ°é£ä¹¦...")
    try:
        fs = FeishuClient(FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_BASE_TOKEN)
        table_id = fs.get_table_id()
        if table_id:
            existing = fs.get_all_records(table_id)
            if existing:
                ids = [r['record_id'] for r in existing]
                for i in range(0, len(ids), 500): fs.delete_records(table_id, ids[i:i+500])
            for i in range(0, len(valid_jobs), 100): fs.add_records(table_id, valid_jobs[i:i+100])
            print(f"ğŸ‰ å¤§åŠŸå‘Šæˆï¼{len(valid_jobs)} æ¡å²—ä½å·²å…¨éƒ¨åŒæ­¥ï¼")
    except Exception as e:
        print(f"  âŒ é£ä¹¦åŒæ­¥å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
